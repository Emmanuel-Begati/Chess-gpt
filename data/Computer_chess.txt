Computer hardware and software capable of playing chess
For other uses, see Computer Chess (film).
1990s pressure-sensory chess computer with LCD screen
This article is part of the series onChess programming
Board representations
0x88
Bitboards

Evaluation functions
Deep neural networks (Transformers)
Attention
Efficiently updatable neural networks
Handcrafted evaluation functions
Piece-square tables
Reinforcement learning
Stochastic gradient descent
Supervised learning
Texel tuning
Unsupervised learning

Graph and tree search algorithms
Minimax
Alpha-beta pruning
Principal variation search
Quiescence search
Monte Carlo tree search

Chess computers
Belle
ChessMachine
ChipTest
Cray Blitz
Deep Blue
Deep Thought
HiTech
Hydra
Mephisto
Saitek

Chess engines
AlphaZero
Chess Tiger
Crafty
CuckooChess
Deep Fritz
Dragon by Komodo Chess
Fairy-Max
Fritz
Fruit
GNU Chess
HIARCS
Houdini
Ikarus
Junior
KnightCap
Komodo
Leela Chess Zero
MChess Pro
Mittens
MuZero
Naum
REBEL
Rybka
Shredder
Sjeng
SmarThink
Stockfish
Torch
Turochamp
Zappa
vte
Computer chess includes both hardware (dedicated computers) and software capable of playing chess. Computer chess provides opportunities for players to practice even in the absence of human opponents, and also provides opportunities for analysis, entertainment and training. Computer chess applications that play at the level of a chess grandmaster or higher are available on hardware from supercomputers to smart phones. Standalone chess-playing machines are also available. Stockfish, Leela Chess Zero, GNU Chess, Fruit, and other free open source applications are available for various platforms.
Computer chess applications, whether implemented in hardware or software, use different strategies than humans to choose their moves: they use heuristic methods to build, search and evaluate trees representing sequences of moves from the current position and attempt to execute the best such sequence during play. Such trees are typically quite large, thousands to millions of nodes. The computational speed of modern computers, capable of processing tens of thousands to hundreds of thousands of nodes or more per second, along with extension and reduction heuristics that narrow the tree to mostly relevant nodes, make such an approach effective.
The first chess machines capable of playing chess or reduced chess-like games were software programs running on digital computers early in the vacuum-tube computer age (1950s). The early programs played so poorly that even a beginner could defeat them.  Within 40 years, in 1997, chess engines running on super-computers or specialized hardware were capable of defeating even the best human players. By 2006, programs running on desktop PCs had attained the same capability. In 2006, Monty Newborn, Professor of Computer Science at McGill University, declared: "the science has been done". Nevertheless, solving chess is not currently possible for modern computers due to the game's extremely large number of possible variations.[1]
Computer chess was once considered the "Drosophila of AI", the edge of knowledge engineering. The field is now considered a scientifically completed paradigm, and playing chess is a mundane computing activity.[2]


Availability and playing strength[edit]
Computer chess IC bearing the name of developer Frans Morsch (see Mephisto)
In the past, stand-alone chess machines (usually microprocessors running software chess programs; occasionally specialized hardware) were sold. Today, chess engines may be installed as software on ordinary devices like smartphones and PCs,[3] either alone or alongside GUI programs such as Chessbase and the mobile apps for Chess.com and Lichess (both primarily websites).[4] Examples of free and open source engines include Stockfish[5] and Leela Chess Zero[6] (Lc0). Chess.com maintains its own proprietary engine named Torch.[7] Some chess engines, including Stockfish, have web versions made in languages like WebAssembly and JavaScript.[8] Most chess programs and sites offer the ability to analyze positions and games using chess engines, and some offer the ability to play against engines (which can be set to play at custom levels of strength) as though they were normal opponents.
Hardware requirements for chess engines are minimal, but performance will vary with processor speed, and memory, needed to hold large transposition tables. 
Most modern chess engines, such as Stockfish, rely on efficiently updatable neural networks, tailored to be run exclusively on CPUs,[9][10] but Lc0 uses networks reliant on GPU performance.[11][12] Top engines such as Stockfish can be expected to beat the world's best players reliably, even when running on consumer-grade hardware.[13]

Types and features of chess software[edit]
Perhaps the most common type of chess software are programs that simply play chess.  A human player makes a move on the board, the AI calculates and plays a subsequent move, and the human and AI alternate turns until the game ends.  The chess engine, which calculates the moves, and the graphical user interface (GUI) are sometimes separate programs.  Different engines can be connected to the GUI, permitting play against different styles of opponent.  Engines often have  a simple text command-line interface, while GUIs may offer a variety of piece sets, board styles, or even 3D or animated pieces.  Because recent engines are so capable, engines or GUIs may offer some way of handicapping the engine's ability, to improve the odds for a win by the human player. Universal Chess Interface (UCI) engines such as Fritz or Rybka may have a built-in mechanism for reducing the Elo rating of the engine (via UCI's uci_limitstrength and uci_elo parameters).  Some versions of Fritz have a Handicap and Fun mode for limiting the current engine or changing the percentage of mistakes it makes or changing its style. Fritz also has a Friend Mode where during the game it tries to match the level of the player.

Screenshot of Chess, a component of macOS
Chess databases allow users to search through a large library of historical games, analyze them, check statistics, and formulate an opening repertoire. Chessbase (for PC) is a common program for these purposes amongst professional players, but there are alternatives such as Shane's Chess Information Database (Scid) [14] for Windows, Mac or Linux, Chess Assistant[15] for PC,[16] Gerhard Kalab's Chess PGN Master for Android[17] or Giordano Vicoli's Chess-Studio for iOS.[18]
Programs such as Playchess allow players to play against one another over the internet.
Chess training programs teach chess. Chessmaster had playthrough tutorials by IM Josh Waitzkin and GM Larry Christiansen. Stefan Meyer-Kahlen offers Shredder Chess Tutor based on the Step coursebooks of Rob Brunia and Cor Van Wijgerden. Former World Champion Magnus Carlsen's Play Magnus company released a Magnus Trainer app for Android and iOS. Chessbase has Fritz and Chesster for children.  Convekta provides a large number of training apps such as CT-ART and its Chess King line based on tutorials by GM Alexander Kalinin and Maxim Blokh.
There is also software for handling chess problems.

Computers versus humans[edit]
Main article: Human–computer chess matches
After discovering refutation screening—the application of alpha–beta pruning to optimizing move evaluation—in 1957, a team at Carnegie Mellon University predicted that a computer would defeat the world human champion by 1967.[19] It did not anticipate the difficulty of determining the right order to evaluate moves. Researchers worked to improve programs' ability to identify killer heuristics, unusually high-scoring moves to reexamine when evaluating other branches, but into the 1970s most top chess players believed that computers would not soon be able to play at a Master level.[20] In 1968, International Master David Levy made a famous bet that no chess computer would be able to beat him within ten years,[21] and in 1976 Senior Master and professor of psychology Eliot Hearst of Indiana University wrote that "the only way a current computer program could ever win a single game against a master player would be for the master, perhaps in a drunken stupor while playing 50 games simultaneously, to commit some once-in-a-year blunder".[20]
In the late 1970s chess programs began defeating highly skilled human players.[20] The year of Hearst's statement, Northwestern University's Chess 4.5 at the Paul Masson American Chess Championship's Class B level became the first to win a human tournament. Levy won his bet in 1978 by beating Chess 4.7, but it achieved the first computer victory against a Master-class player at the tournament level by winning one of the six games.[21] In 1980, Belle began often defeating Masters. By 1982 two programs played at Master level and three were slightly weaker.[20]
The sudden improvement without a theoretical breakthrough was unexpected, as many did not expect that Belle's ability to examine 100,000 positions a second—about eight plies—would be sufficient. The Spracklens, creators of the successful microcomputer program Sargon, estimated that 90% of the improvement came from faster evaluation speed and only 10% from improved evaluations. New Scientist stated in 1982 that computers "play terrible chess ... clumsy, inefficient, diffuse, and just plain ugly", but humans lost to them by making "horrible blunders, astonishing lapses, incomprehensible oversights, gross miscalculations, and the like" much more often than they realized; "in short, computers win primarily through their ability to find and exploit miscalculations in human initiatives".[20]
By 1982, microcomputer chess programs could evaluate up to 1,500 moves a second and were as strong as mainframe chess programs of five years earlier, able to defeat a majority of amateur players. While only able to look ahead one or two plies more than at their debut in the mid-1970s, doing so improved their play more than experts expected; seemingly minor improvements "appear to have allowed the crossing of a psychological threshold, after which a rich harvest of human error becomes accessible", New Scientist wrote.[20] While reviewing SPOC in 1984, BYTE wrote that "Computers—mainframes, minis, and micros—tend to play ugly, inelegant chess", but noted Robert Byrne's statement that "tactically they are freer from error than the average human player". The magazine described SPOC as a "state-of-the-art chess program" for the IBM PC with a "surprisingly high" level of play, and estimated its USCF rating as 1700 (Class B).[22]
At the 1982 North American Computer Chess Championship, Monroe Newborn predicted that a chess program could become world champion within five years; tournament director and International Master Michael Valvo predicted ten years; the Spracklens predicted 15; Ken Thompson predicted more than 20; and others predicted that it would never happen. The most widely held opinion, however, stated that it would occur around the year 2000.[23] In 1989, Levy was defeated by Deep Thought in an exhibition match. Deep Thought, however, was still considerably below World Championship level, as the reigning world champion, Garry Kasparov, demonstrated in two strong wins in 1989. It was not until a 1996 match with IBM's Deep Blue that Kasparov lost his first game to a computer at tournament time controls in Deep Blue versus Kasparov, 1996, game 1. This game was, in fact, the first time a reigning world champion had lost to a computer using regular time controls. However, Kasparov regrouped to win three and draw two of the remaining five games of the match, for a convincing victory.
In May 1997, an updated version of Deep Blue defeated Kasparov 3½–2½ in a return match. A documentary mainly about the confrontation was made in 2003, titled Game Over: Kasparov and the Machine.

Deep Blue vs. Kasparov, 1996, game 1
abcdefgh8877665544332211abcdefghFinal position

With increasing processing power and improved evaluation functions, chess programs running on commercially available workstations began to rival top-flight players. In 1998, Rebel 10 defeated Viswanathan Anand, who at the time was ranked second in the world, by a score of 5–3. However, most of those games were not played at normal time controls. Out of the eight games, four were blitz games (five minutes plus five seconds Fischer delay for each move); these Rebel won 3–1. Two were semi-blitz games (fifteen minutes for each side) that Rebel won as well (1½–½). Finally, two games were played as regular tournament games (forty moves in two hours, one hour sudden death); here it was Anand who won ½–1½.[24] In fast games, computers played better than humans, but at classical time controls – at which a player's rating is determined – the advantage was not so clear.
In the early 2000s, commercially available programs such as Junior and Fritz were able to draw matches against former world champion Garry Kasparov and classical world champion Vladimir Kramnik.
In October 2002, Vladimir Kramnik and Deep Fritz competed in the eight-game Brains in Bahrain match, which ended in a draw. Kramnik won games 2 and 3 by "conventional" anti-computer tactics – play conservatively for a long-term advantage the computer is not able to see in its game tree search. Fritz, however, won game 5 after a severe blunder by Kramnik. Game 6 was described by the tournament commentators as "spectacular".  Kramnik, in a better position in the early middlegame, tried a piece sacrifice to achieve a strong tactical attack, a strategy known to be highly risky against computers who are at their strongest defending against such attacks. True to form, Fritz found a watertight defense and Kramnik's attack petered out leaving him in a bad position. Kramnik resigned the game, believing the position lost. However, post-game human and computer analysis has shown that the Fritz program was unlikely to have been able to force a win and Kramnik effectively sacrificed a drawn position. The final two games were draws.  Given the circumstances, most commentators still rate Kramnik the stronger player in the match.[citation needed]
In January 2003, Kasparov played Junior, another chess computer program, in New York City. The match ended 3–3.
In November 2003, Kasparov played X3D Fritz.  The match ended 2–2.
In 2005, Hydra, a dedicated chess computer with custom hardware and sixty-four processors and also winner of the 14th IPCCC in 2005, defeated seventh-ranked Michael Adams 5½–½ in a six-game match (though Adams' preparation was far less thorough than Kramnik's for the 2002 series).[25]
In November–December 2006, World Champion Vladimir Kramnik played Deep Fritz.  This time the computer won; the match ended 2–4. Kramnik was able to view the computer's opening book. In the first five games Kramnik steered the game into a typical "anti-computer" positional contest. He lost one game (overlooking a mate in one), and drew the next four. In the final game, in an attempt to draw the match, Kramnik played the more aggressive Sicilian Defence and was crushed.
There was speculation that interest in human–computer chess competition would plummet as a result of the 2006 Kramnik-Deep Fritz match.[26] According to Newborn, for example, "the science is done".[27]
Human–computer chess matches showed the best computer systems overtaking human chess champions in the late 1990s. For the 40 years prior to that, the trend had been that the best machines gained about 40 points per year in the Elo rating while the best humans only gained roughly 2 points per year.[28] The highest rating obtained by a computer in human competition was Deep Thought's USCF rating of 2551 in 1988 and FIDE no longer accepts human–computer results in their rating lists. Specialized machine-only Elo pools have been created for rating machines, but such numbers, while similar in appearance, are not directly compared.[29] In 2016, the Swedish Chess Computer Association rated computer program Komodo at 3361.
Chess engines continue to improve. In 2009, chess engines running on slower hardware reached the grandmaster level. A mobile phone won a category 6 tournament with a performance rating 2898: chess engine Hiarcs 13 running inside Pocket Fritz 4 on the mobile phone HTC Touch HD won the Copa Mercosur tournament in Buenos Aires, Argentina with 9 wins and 1 draw on August 4–14, 2009.[30] Pocket Fritz 4 searches fewer than 20,000 positions per second.[31] This is in contrast to supercomputers such as Deep Blue that searched 200 million positions per second.
Advanced Chess is a form of chess developed in 1998 by Kasparov where a human plays against another human, and both have access to computers to enhance their strength. The resulting "advanced" player was argued by Kasparov to be stronger than a human or computer alone. This has been proven in numerous occasions, such as at Freestyle Chess events.
Players today are inclined to treat chess engines as analysis tools rather than opponents.[32] Chess grandmaster Andrew Soltis stated in 2016 "The computers are just much too good" and that world champion Magnus Carlsen won't play computer chess because "he just loses all the time and there's nothing more depressing than losing without even being in the game."[33]

Computer methods[edit]
Since the era of mechanical machines that played rook and king endings and electrical machines that played other games like hex in the early years of the 20th century, scientists and theoreticians have sought to develop a procedural representation of how humans learn, remember, think and apply knowledge, and the game of chess, because of its daunting complexity, became the "Drosophila of artificial intelligence (AI)".[Note 1] The procedural resolution of complexity became synonymous with thinking, and early computers, even before the chess automaton era, were popularly referred to as "electronic brains".  Several different schema were devised starting in the latter half of the 20th century to represent knowledge and thinking, as applied to playing the game of chess (and other games like checkers):

Search based (brute force vs selective search)
Search in search based schema (minimax/alpha-beta, Monte Carlo tree search)
Evaluations in search based schema (machine learning, neural networks, texel tuning, genetic algorithms, gradient descent, reinforcement learning)
Knowledge based (PARADISE, endgame tablebases)
Using "ends-and-means" heuristics a human chess player can intuitively determine optimal outcomes and how to achieve them regardless of the number of moves necessary, but a computer must be systematic in its analysis. Most players agree that looking at least five moves ahead (ten plies) when necessary is required to play well. Normal tournament rules give each player an average of three minutes per move. On average there are more than 30 legal moves per chess position, so a computer must examine a quadrillion possibilities to look ahead ten plies (five full moves); one that could examine a million positions a second would require more than 30 years.[20]
The earliest attempts at procedural representations of playing chess predated the digital electronic age, but it was the stored program digital computer that gave scope to calculating such complexity.  Claude Shannon, in 1949, laid out the principles of algorithmic solution of chess.  In that paper, the game is represented by a "tree", or digital data structure of choices (branches) corresponding to moves.  The nodes of the tree were positions on the board resulting from the choices of move.  The impossibility of representing an entire game of chess by constructing a tree from first move to last was immediately apparent: there are an average of 36 moves per position in chess and an average game lasts about 35 moves to resignation (60-80 moves if played to checkmate, stalemate, or other draw). There are 400 positions possible after the first move by each player, about 200,000 after two moves each, and nearly 120 million after just 3 moves each.
So a limited lookahead (search) to some depth, followed by using domain-specific knowledge to evaluate the resulting terminal positions was proposed. A kind of middle-ground position, given good moves by both sides, would result, and its evaluation would inform the player about the goodness or badness of the moves chosen. Searching and comparing operations on the tree were well suited to computer calculation; the representation of subtle chess knowledge in the evaluation function was not.  The early chess programs suffered in both areas: searching the vast tree required computational resources far beyond those available, and what chess knowledge was useful and how it was to be encoded would take decades to discover.
The developers of a chess-playing computer system must decide on a number of fundamental implementation issues. These include:

Graphical user interface (GUI) – how moves are entered and communicated to the user, how the game is recorded, how the time controls are set, and other interface considerations
Board representation – how a single position is represented in data structures;
Search techniques – how to identify the possible moves and select the most promising ones for further examination;
Leaf evaluation – how to evaluate the value of a board position, if no further search will be done from that position.
Adriaan de Groot interviewed a number of chess players of varying strengths, and concluded that both masters and beginners look at around forty to fifty positions before deciding which move to play. What makes the former much better players is that they use pattern recognition skills built from experience. This enables them to examine some lines in much greater depth than others by simply not considering moves they can assume to be poor. More evidence for this being the case is the way that good human players find it much easier to recall positions from genuine chess games, breaking them down into a small number of recognizable sub-positions, rather than completely random arrangements of the same pieces. In contrast, poor players have the same level of recall for both.
The equivalent of this in computer chess are evaluation functions for leaf evaluation, which correspond to the human players' pattern recognition skills, and the use of machine learning techniques in training them, such as Texel tuning, stochastic gradient descent, and reinforcement learning, which corresponds to building experience in human players. This allows modern programs to examine some lines in much greater depth than others by using forwards pruning and other selective heuristics to simply not consider moves the program assume to be poor through their evaluation function, in the same way that human players do. The only fundamental difference between a computer program and a human in this sense is that a computer program can search much deeper than a human player could, allowing it to search more nodes and bypass the horizon effect to a much greater extent than is possible with human players.

Graphical user interface[edit]
Computer chess programs usually support a number of common de facto standards. Nearly all of today's programs can read and write game moves as Portable Game Notation (PGN), and can read and write individual positions as Forsyth–Edwards Notation (FEN). Older chess programs often only understood long algebraic notation, but today users expect chess programs to understand standard algebraic chess notation.
Starting in the late 1990s, programmers began to develop separately engines (with a command-line interface which calculates which moves are strongest in a position) or a graphical user interface (GUI) which provides the player with a chessboard they can see, and pieces that can be moved.  Engines communicate their moves to the GUI using a protocol such as the Chess Engine Communication Protocol (CECP) or Universal Chess Interface (UCI). By dividing chess programs into these two pieces, developers can write only the user interface, or only the engine, without needing to write both parts of the program. (See also chess engine.)
Developers have to decide whether to connect the engine to an opening book and/or endgame tablebases or leave this to the GUI.

Board representations[edit]
Main article: Board representation (chess)
The data structure used to represent each chess position is key to the performance of move generation and position evaluation. Methods include pieces stored in an array ("mailbox" and "0x88"), piece positions stored in a list ("piece list"), collections of bit-sets for piece locations ("bitboards"), and huffman coded positions for compact long-term storage.

Search techniques[edit]
Computer chess programs consider chess moves as a game tree. In theory, they examine all moves, then all counter-moves to those moves, then all moves countering them, and so on, where each individual move by one player is called a "ply". This evaluation continues until a certain maximum search depth or the program determines that a final "leaf" position has been reached (e.g. checkmate).

Minimax search[edit]
Further information: Alpha–beta pruning and minimax
One particular type of search algorithm used in computer chess are minimax search algorithms, where at each ply the "best" move by the player is selected; one player is trying to maximize the score, the other to minimize it. By this alternating process, one particular terminal node whose evaluation represents the searched value of the position will be arrived at.  Its value is backed up to the root, and that evaluation becomes the valuation of the position on the board.  This search process is called minimax.
A naive implementation of the minimax algorithm can only search to a small depth in a practical amount of time, so various methods have been devised to greatly speed the search for good moves. Alpha–beta pruning, a system of defining upper and lower bounds on possible search results and searching until the bounds coincided, is typically used to reduce the search space of the program.
In addition, various selective search heuristics, such as quiescence search, forward pruning, search extensions and search reductions, are also used as well. These heuristics are triggered based on certain conditions in an attempt to weed out obviously bad moves (history moves) or to investigate interesting nodes (e.g. check extensions, passed pawns on seventh rank, etc.). These selective search heuristics have to be used very carefully however. If the program overextends, it wastes too much time looking at uninteresting positions. If too much is pruned or reduced, there is a risk of cutting out interesting nodes.

Monte Carlo tree search[edit]
Further information: Monte Carlo tree search
Monte Carlo tree search (MCTS) is a heuristic search algorithm which expands the search tree based on random sampling of the search space. A version of Monte Carlo tree search commonly used in computer chess is PUCT, Predictor and Upper Confidence bounds applied to Trees.
DeepMind's AlphaZero and Leela Chess Zero uses MCTS instead of minimax. Such engines use batching on graphics processing units in order to calculate their evaluation functions and policy (move selection), and therefore require a parallel search algorithm as calculations on the GPU are inherently parallel. The minimax and alpha-beta pruning algorithms used in computer chess are inherently serial algorithms, so would not work well with batching on the GPU. On the other hand, MCTS is a good alternative, because the random sampling used in Monte Carlo tree search lends itself well to parallel computing, and is why nearly all engines which support calculations on the GPU use MCTS instead of alpha-beta.

Other optimizations[edit]
Many other optimizations can be used to make chess-playing programs stronger. For example, transposition tables are used to record positions that have been previously evaluated, to save recalculation of them. Refutation tables record key moves that "refute" what appears to be a good move; these are typically tried first in variant positions (since a move that refutes one position is likely to refute another).  The drawback is that transposition tables at deep ply depths can get quite large – tens to hundreds of millions of entries. IBM's Deep Blue transposition table in 1996, for example was 500 million entries. Transposition tables that are too small can result in spending more time searching for non-existent entries due to threshing than the time saved by entries found. Many chess engines use pondering, searching to deeper levels on the opponent's time, similar to human beings, to increase their playing strength.
Of course, faster hardware and additional memory can improve chess program playing strength.  Hyperthreaded architectures can improve performance modestly if the program is running on a single core or a small number of cores.  Most modern programs are designed to take advantage of multiple cores to do parallel search.  Other programs are designed to run on a general purpose computer and allocate move generation, parallel search, or evaluation to dedicated processors or specialized co-processors.

History[edit]
The first paper on chess search was by Claude Shannon in 1950.[34] He predicted the two main possible search strategies which would be used, which he labeled "Type A" and "Type B",[35] before anyone had programmed a computer to play chess.
Type A programs would use a "brute force" approach, examining every possible position for a fixed number of moves using a pure naive minimax algorithm. Shannon believed this would be impractical for two reasons.
First, with approximately thirty moves possible in a typical real-life position, he expected that searching the approximately 109 positions involved in looking three moves ahead for both sides (six plies) would take about sixteen minutes, even in the "very optimistic" case that the chess computer evaluated a million positions every second. (It took about forty years to achieve this speed.) A later search algorithm called alpha–beta pruning, a system of defining upper and lower bounds on possible search results and searching until the bounds coincided, reduced the branching factor of the game tree logarithmically, but it still was not feasible for chess programs at the time to exploit the exponential explosion of the tree.
Second, it ignored the problem of quiescence, trying to only evaluate a position that is at the end of an exchange of pieces or other important sequence of moves ('lines'). He expected that adapting minimax to cope with this would greatly increase the number of positions needing to be looked at and slow the program down still further. He expected that adapting type A to cope with this would greatly increase the number of positions needing to be looked at and slow the program down still further.
This led naturally to what is referred to as "selective search" or "type B search", using chess knowledge (heuristics) to select a few presumably good moves from each position to search, and prune away the others without searching. Instead of wasting processing power examining bad or trivial moves, Shannon suggested that type B programs would use two improvements:

Employ a quiescence search.
Employ forward pruning; i.e. only look at a few good moves for each position.
This would enable them to look further ahead ('deeper') at the most significant lines in a reasonable time. However, early attempts at selective search often resulted in the best move or moves being pruned away. As a result, little or no progress was made for the next 25 years dominated by this first iteration of the selective search paradigm. The best program produced in this early period was Mac Hack VI in 1967; it played at the about the same level as the average amateur (C class on the United States Chess Federation rating scale).
Meanwhile, hardware continued to improve, and in 1974, brute force searching was implemented for the first time in the Northwestern University Chess 4.0 program. In this approach, all alternative moves at a node are searched, and none are pruned away. They discovered that the time required to simply search all the moves was much less than the time required to apply knowledge-intensive heuristics to select just a few of them, and the benefit of not prematurely or inadvertently pruning away good moves resulted in substantially stronger performance.
In the 1980s and 1990s, progress was finally made in the selective search paradigm, with the development of quiescence search, null move pruning, and other modern selective search heuristics. These heuristics had far fewer mistakes than earlier heuristics did, and was found to be worth the extra time it saved because it could search deeper and widely adopted by many engines. While many modern programs do use alpha-beta search as a substrate for their search algorithm, these additional selective search heuristics used in modern programs means that the program no longer does a "brute force" search. Instead they heavily rely on these selective search heuristics to extend lines the program considers good and prune and reduce lines the program considers bad, to the point where most of the nodes on the search tree are pruned away, enabling modern programs to search very deep.
In 2006, Rémi Coulom created Monte Carlo tree search, another kind of type B selective search. In 2007, an adaption of Monte Carlo tree search called Upper Confidence bounds applied to Trees or UCT for short was created by Levente Kocsis and Csaba Szepesvári. In 2011, Chris Rosin developed a variation of UCT called Predictor + Upper Confidence bounds applied to Trees, or PUCT for short. PUCT was then used in AlphaZero in 2017, and later in Leela Chess Zero in 2018.

Knowledge versus search (processor speed)[edit]
In the 1970s, most chess programs ran on super computers like Control Data Cyber 176s or Cray-1s, indicative that during that developmental period for computer chess, processing power was the limiting factor in performance.  Most chess programs struggled to search to a depth greater than 3 ply.  It was not until the hardware chess machines of the 1980s, that a relationship between processor speed and knowledge encoded in the evaluation function became apparent.
It has been estimated that doubling the computer speed gains approximately fifty to seventy Elo points in playing strength (Levy & Newborn 1991:192).

Leaf evaluation[edit]
Main article: Evaluation function
For most chess positions, computers cannot look ahead to all possible final positions. Instead, they must look ahead a few plies and compare the possible positions, known as leaves. The algorithm that evaluates leaves is termed the "evaluation function", and these algorithms are often vastly different between different chess programs. Evaluation functions typically evaluate positions in hundredths of a pawn (called a centipawn), where by convention, a positive evaluation favors White, and a negative evaluation favors Black. However, some evaluation function output win/draw/loss percentages instead of centipawns.
Historically, handcrafted evaluation functions consider material value along with other factors affecting the strength of each side. When counting up the material for each side, typical values for pieces are 1 point for a pawn, 3 points for a knight or bishop, 5 points for a rook, and 9 points for a queen. (See Chess piece relative value.) The king is sometimes given an arbitrarily high value such as 200 points (Shannon's paper) to ensure that a checkmate outweighs all other factors (Levy & Newborn 1991:45). In addition to points for pieces, most handcrafted evaluation functions take many factors into account, such as pawn structure, the fact that a pair of bishops are usually worth more, centralized pieces are worth more, and so on. The protection of kings is usually considered, as well as the phase of the game (opening, middle or endgame). Machine learning techniques such as Texel turning, stochastic gradient descent, or reinforcement learning are usually used to optimise handcrafted evaluation functions.
Most modern evaluation functions make use of neural networks. The most common evaluation function in use today is the efficiently updatable neural network, which is a shallow neural network whose inputs are piece-square tables. Piece-square tables are a set of 64 values corresponding to the squares of the chessboard, and there typically exists a piece-square table for every piece and colour, resulting in 12 piece-square tables and thus 768 inputs into the neural network. In addition, some engines use deep neural networks in their evaluation function. Neural networks are usually trained using some reinforcement learning algorithm, in conjunction with supervised learning or unsupervised learning.
The output of the evaluation function is a single scalar, quantized in centipawns or other units, which is, in the case of handcrafted evaluation functions, a weighted summation of the various factors described, or in the case of neural network based evaluation functions, the output of the head of the neural network. The evaluation putatively represents or approximates the value of the subtree below the evaluated node as if it had been searched to termination, i.e. the end of the game.  During the search, an evaluation is compared against evaluations of other leaves, eliminating nodes that represent bad or poor moves for either side, to yield a node which by convergence, represents the value of the position with best play by both sides.

Endgame tablebases[edit]
Main article: Endgame tablebase
Endgame play had long been one of the great weaknesses of chess programs because of the depth of search needed. Some otherwise master-level programs were unable to win in positions where even intermediate human players could force a win.
To solve this problem, computers have been used to analyze some chess endgame positions completely, starting with king and pawn against king. Such endgame tablebases are generated in advance using a form of retrograde analysis, starting with positions where the final result is known (e.g., where one side has been mated) and seeing which other positions are one move away from them, then which are one move from those, etc. Ken Thompson was a pioneer in this area.
The results of the computer analysis sometimes surprised people. In 1977 Thompson's Belle chess machine used the endgame tablebase for a king and rook against king and queen and was able to draw that theoretically lost ending against several masters (see Philidor position#Queen versus rook).  This was despite not following the usual strategy to delay defeat by keeping the defending king and rook close together for as long as possible. Asked to explain the reasons behind some of the program's moves, Thompson was unable to do so beyond saying the program's database simply returned the best moves.
Most grandmasters declined to play against the computer in the queen versus rook endgame, but Walter Browne accepted the challenge.  A queen versus rook position was set up in which the queen can win in thirty moves, with perfect play.  Browne was allowed 2½ hours to play fifty moves, otherwise a draw would be claimed under the fifty-move rule.  After forty-five moves, Browne agreed to a draw, being unable to force checkmate or win the rook within the next five moves. In the final position, Browne was still seventeen moves away from checkmate, but not quite that far away from winning the rook.  Browne studied the endgame, and played the computer again a week later in a different position in which the queen can win in thirty moves.  This time, he captured the rook on the fiftieth move, giving him a winning position.[36][37]
Other positions, long believed to be won, turned out to take more moves against perfect play to actually win than were allowed by chess's fifty-move rule. As a consequence, for some years the official FIDE rules of chess were changed to extend the number of moves allowed in these endings. After a while, the rule reverted to fifty moves in all positions –  more such positions were discovered, complicating the rule still further, and it made no difference in human play, as they could not play the positions perfectly.
Over the years, other endgame database formats have been released including the Edward Tablebase, the De Koning Database and the Nalimov Tablebase which is used by many chess programs such as Rybka, Shredder and Fritz. Tablebases for all positions with six pieces are available.[38] Some seven-piece endgames have been analyzed by Marc Bourzutschky and Yakov Konoval.[39] Programmers using the Lomonosov supercomputers in Moscow have completed a chess tablebase for all endgames with seven pieces or fewer (trivial endgame positions are excluded, such as six white pieces versus a lone black king).[40][41] In all of these endgame databases it is assumed that castling is no longer possible.
Many tablebases do not consider the fifty-move rule, under which a game where fifty moves pass without a capture or pawn move can be claimed to be a draw by either player. This results in the tablebase returning results such as "Forced mate in sixty-six moves" in some positions which would actually be drawn because of the fifty-move rule. One reason for this is that if the rules of chess were to be changed once more, giving more time to win such positions, it will not be necessary to regenerate all the tablebases. It is also very easy for the program using the tablebases to notice and take account of this 'feature' and in any case if using an endgame tablebase will choose the move that leads to the quickest win (even if it would fall foul of the fifty-move rule with perfect play). If playing an opponent not using a tablebase, such a choice will give good chances of winning within fifty moves.
The Nalimov tablebases, which use state-of-the-art compression techniques, require 7.05 GB of hard disk space for all five-piece endings. To cover all the six-piece endings requires approximately 1.2 TB. It is estimated that a seven-piece tablebase requires between 50 and 200 TB of storage space.[42]
Endgame databases featured prominently in 1999, when Kasparov played an exhibition match on the Internet against the rest of the world. A seven piece Queen and pawn endgame was reached with the World Team fighting to salvage a draw. Eugene Nalimov helped by generating the six piece ending tablebase where both sides had two Queens which was used heavily to aid analysis by both sides.
The most popular endgame tablebase is syzygy which is used by most top computer programs like Stockfish, Leela Chess Zero, and Komodo. It is also significantly smaller in size than other formats, with 7-piece tablebases taking only 18.4 TB.[43]
For a current state-of-the art chess engine like Stockfish, a table base only provides a very minor increase in playing strength (approximately 3 Elo points for syzygy 6men as of Stockfish 15).[44]

Opening book[edit]
Chess engines, like human beings, may save processing time as well as select variations known to be strong via referencing an opening book stored in a database.  Opening books cover the opening moves of a game to variable depth, depending on opening and variation, but usually to the first 10-12 moves (20-24 ply).  In the early eras of computer chess, trusting variations studied in-depth by human grandmasters for decades was superior to the weak performance of mid-20th-century engines.  And even in the contemporary era, allowing computer engines to extensively analyze various openings at their leisure beforehand, and then simply consult the results when in a game, speeds up their play.
In the 1990s, some theorists believed that chess engines of the day had much of their strength in memorized opening books and knowledge dedicated to known positions, and thus believed a valid anti-computer tactic would be to intentionally play some out-of-book moves in order to force the chess program to think for itself.  This seems to have been a dubious assumption even then; Garry Kasparov tried it via using the non-standard Mieses Opening at the 1997 Deep Blue versus Garry Kasparov Game 1 match, but lost.  This tactic became even weaker as time passed; the opening books stored in computer databases can be far more extensive than even the best prepared humans, meaning computers will be well-prepared for even rare variations and know the correct play.  More generally, the play of engines even in fully unknown situations (as comes up in variants such as Chess960) is still exceptionally strong, so the lack of an opening book isn't even a major disadvantage for tactically sharp chess engines, who can discover strong moves in unfamiliar board variations accurately.
In contemporary engine tournaments, engines are often told to play situations from a variety of openings, including unbalanced ones, to reduce the draw rate and to add more variety to the games.[45]

Computer chess rating lists[edit]
See also: Chess engine § Ratings
CEGT,[46] CSS,[47] SSDF,[48] WBEC,[49] REBEL,[50] FGRL,[51] and IPON[52] maintain rating lists allowing fans to compare the strength of engines. Various versions of Stockfish, Komodo, Leela Chess Zero, and Fat Fritz dominate the rating lists in the early 2020s.
CCRL  (Computer Chess Rating Lists) is an organisation that tests computer chess engines' strength by playing the programs against each other. CCRL was founded in 2006 to promote computer-computer competition and tabulate results on a rating list.[53]
The organisation runs three different lists: 40/40 (40 minutes for every 40 moves played), 40/4 (4 minutes for every 40 moves played), and 40/4 FRC (same time control but Chess960).[Note 2] Pondering (or permanent brain) is switched off and timing is adjusted to the AMD64 X2 4600+ (2.4 GHz) CPU by using Crafty 19.17 BH as a benchmark. Generic, neutral opening books are used (as opposed to the engine's own book) up to a limit of 12 moves into the game alongside 4 or 5 man tablebases.[53][54][55]

History[edit]
Pre-computer age[edit]
El Ajedrecista
The idea of creating a chess-playing machine dates back to the eighteenth century.  Around 1769, the chess playing automaton called The Turk, created by Hungarian inventor Farkas Kempelen, became famous before being exposed as a hoax. Before the development of digital computing, serious trials based on automata such as El Ajedrecista of 1912, built by Spanish engineer Leonardo Torres Quevedo, which played a king and rook versus king ending, were too complex and limited to be useful for playing full games of chess. The field of mechanical chess research languished until the advent of the digital computer in the 1950s.

Early software age: selective search and Botvinnik[edit]
Since then, chess enthusiasts and computer engineers have built, with increasing degrees of seriousness and success, chess-playing machines and computer programs. One of the few chess grandmasters to devote himself seriously to computer chess was former World Chess Champion Mikhail Botvinnik, who wrote several works on the subject. Botvinnik's interest in Computer Chess started in the 50s, favouring chess algorithms based on Shannon's selective type B strategy, as discussed along with Max Euwe 1958 in Dutch Television. Working with relatively primitive hardware available in the Soviet Union in the early 1960s, Botvinnik had no choice but to investigate software move selection techniques; at the time only the most powerful computers could achieve much beyond a three-ply full-width search, and Botvinnik had no such machines.  In 1965 Botvinnik was a consultant to the ITEP team in a US-Soviet computer chess match which won a correspondence chess match against the Kotok-McCarthy-Program led by John McCarthy in 1967.(see Kotok-McCarthy). Later he advised the team that created the chess program Kaissa at Moscow's Institute of Control Sciences. Botvinnik had his own ideas to model a Chess Master's Mind. After publishing and discussing his early ideas on attack maps and trajectories at Moscow Central Chess Clubin 1966, he found Vladimir Butenko as supporter and collaborator. Butenko first implemented the 15x15 vector attacks board representation on a M-20 computer, determining trajectories. After Botvinnik introduced the concept of Zones in 1970, Butenko refused further cooperation and began to write his own program, dubbed Eureka. In the 70s and 80s, leading a team around Boris Stilman, Alexander Yudin, Alexander Reznitskiy, Michael Tsfasman and Mikhail Chudakov, Botvinnik worked on his own project 'Pioneer' - which was an Artificial Intelligence based chess project. In the 90s, Botvinnik already in his 80s, he worked on the new project 'CC Sapiens'.

Later software age: full-width search[edit]
One developmental milestone occurred when the team from Northwestern University, which was responsible for the Chess series of programs and won the first three ACM Computer Chess Championships (1970–72), abandoned type B searching in 1973. The resulting program, Chess 4.0, won that year's championship and its successors went on to come in second in both the 1974 ACM Championship and that year's inaugural World Computer Chess Championship, before winning the ACM Championship again in 1975, 1976 and 1977.  The type A implementation turned out to be just as fast: in the time it used to take to decide which moves were worthy of being searched, it was possible just to search all of them. In fact, Chess 4.0 set the paradigm that was and still is followed essentially by all modern Chess programs today, and that had been successfully started by the Russian ITEP in 1965.

Rise of chess machines[edit]
In 1978, an early rendition of Ken Thompson's hardware chess machine Belle, entered and won the North American Computer Chess Championship over the dominant Northwestern University Chess 4.7.

Microcomputer revolution[edit]
Technological advances by orders of magnitude in processing power have made the brute force approach far more incisive than was the case in the early years.  The result is that a very solid, tactical AI player aided by some limited positional knowledge built in by the evaluation function and pruning/extension rules began to match the best players in the world. It turned out to produce excellent results, at least in the field of chess, to let computers do what they do best (calculate) rather than coax them into imitating human thought processes and knowledge.  In 1997 Deep Blue, a brute-force machine capable of examining 500 million nodes per second, defeated World Champion Garry Kasparov, marking the first time a computer has defeated a reigning world chess champion in standard time control.

Super-human chess[edit]
In 2016, NPR asked experts to characterize the playing style of computer chess engines. Murray Campbell of IBM stated that "Computers don't have any sense of aesthetics... They play what they think is the objectively best move in any position, even if it looks absurd, and they can play any move no matter how ugly it is." Grandmasters Andrew Soltis and Susan Polgar stated that computers are more likely to retreat than humans are.[33]

Neural network revolution[edit]
While neural networks have been used in the evaluation functions of chess engines since the late 1980s, with programs such as NeuroChess, Morph, Blondie25, Giraffe, AlphaZero, and MuZero,[56][57][58][59][60] neural networks did not become widely adopted by chess engines until the arrival of efficiently updatable neural networks in the summer of 2020. Efficiently updatable neural networks were originally developed in computer shogi in 2018 by Yu Nasu,[61][62] and had to be first ported to a derivative of Stockfish called Stockfish NNUE on 31 May 2020,[63] and integrated into the official Stockfish engine on 6 August 2020,[64][65] before other chess programmers began to adopt neural networks into their engines.
Some people, such as the Royal Society's Venki Ramakrishnan, believe that AlphaZero lead to the widespread adoption of neural networks in chess engines.[66] However, AlphaZero influenced very few engines to begin using neural networks, and those tended to be new experimental engines such as Leela Chess Zero, which began specifically to replicate the AlphaZero paper. The deep neural networks used in AlphaZero's evaluation function required expensive graphics processing units, which were not compatible with existing chess engines. The vast majority of chess engines only use central processing units, and computing and processing information on the GPUs require special libraries in the backend such as Nvidia's CUDA, which none of the engines had access to. Thus the vast majority of chess engines such as Komodo and Stockfish continued to use handcrafted evaluation functions until efficiently updatable neural networks were ported to computer chess from computer shogi in 2020, which did not require either the use of GPUs or libraries like CUDA at all. Even then, the neural networks used in computer chess are fairly shallow, and the deep reinforcement learning methods pioneered by AlphaZero are still extremely rare in computer chess.

Timeline[edit]
1769 – Wolfgang von Kempelen builds the Turk. Presented as a chess-playing automaton, it is secretly operated by a human player hidden inside the machine.
1868 – Charles Hooper presents the Ajeeb automaton –  which also has a human chess player hidden inside.
1912 – Leonardo Torres y Quevedo builds El Ajedrecista, a machine that could play King and Rook versus King endgames.
1941 – Predating comparable work by at least a decade, Konrad Zuse develops computer chess algorithms in his Plankalkül programming formalism. Because of the circumstances of the Second World War, however, they were not published, and did not come to light, until the 1970s.
1948 – Norbert Wiener's book Cybernetics describes how a chess program could be developed using a depth-limited minimax search with an evaluation function.
1950 – Claude Shannon publishes "Programming a Computer for Playing Chess", one of the first papers on the algorithmic methods of computer chess.
1951 – Alan Turing is first to publish a program, developed on paper, that was capable of playing a full game of chess (dubbed Turochamp).[67][68]
1952 – Dietrich Prinz develops a program that solves chess problems.



abcdef
665544332211abcdef

 Los Alamos chess. This simplified version of chess was played in 1956 by the MANIAC I computer.


1956 – Los Alamos chess is the first program to play a chess-like game, developed by Paul Stein and Mark Wells for the MANIAC I computer.
1956 – John McCarthy invents the alpha–beta search algorithm.
1957 – The first programs that can play a full game of chess are developed, one by Alex Bernstein[69] and one by Russian programmers using a BESM.
1958 – NSS becomes the first chess program to use the alpha–beta search algorithm.
1962 – The first program to play credibly, Kotok-McCarthy, is published at MIT.
1963 – Grandmaster David Bronstein defeats an M-20 running an early chess program.[70]
1966–67 – The first chess match between computer programs is played. Moscow Institute for Theoretical and Experimental Physics (ITEP) defeats Kotok-McCarthy at Stanford University by telegraph over nine months.
1967 – Mac Hack VI, by Richard Greenblatt et al. introduces transposition tables and employs dozens of carefully tuned move selection heuristics; it becomes the first program to defeat a person in tournament play.  Mac Hack VI played about C class level.
1968 – Scottish chess champion David Levy makes a 500 pound bet with AI pioneers John McCarthy and Donald Michie that no computer program would win a chess match against him within 10 years.
1970 – Monty Newborn and the Association for Computing Machinery organize the first North American Computer Chess Championships in New York.
1971 – Ken Thompson, an American Computer scientist at Bell Labs and creator of the Unix operating system, writes his first chess-playing program called "chess" for the earliest version of Unix.[71]
1974 – David Levy, Ben Mittman and Monty Newborn organize the first World Computer Chess Championship which is won by the Russian program Kaissa.
1975 – After nearly a decade of only marginal progress since the high-water mark of Greenblatt's MacHack VI in 1967, Northwestern University Chess 4.5 is introduced featuring full-width search, and innovations of bitboards and iterative deepening. It also reinstated a transposition table as first seen in Greenblatt's program. It was thus the first program with an integrated modern structure and became the model for all future development. Chess 4.5 played strong B-class and won the 3rd World Computer Chess Championship the next year.[72] Northwestern University Chess and its descendants dominated computer chess until the era of hardware chess machines in the early 1980s.
1976 – In December, Canadian programmer Peter R. Jennings releases Microchess, the first game for microcomputers to be sold.[73]
Released in 1977, Boris was one of the first chess computers to be widely marketed. It ran on a Fairchild F8 8-bit microprocessor with only 2.5 KiB ROM and 256 byte RAM.
1977 – In March, Fidelity Electronics releases Chess Challenger, the first dedicated chess computer to be sold. The International Computer Chess Association is founded by chess programmers to organize computer chess championships and report on research and advancements on computer chess in their journal. Also that year, Applied Concepts released Boris, a dedicated chess computer in a wooden box with plastic chess pieces and a folding board.
1978 – David Levy wins the bet made 10 years earlier, defeating Chess 4.7 in a six-game match by a score of 4½–1½. The computer's victory in game four is the first defeat of a human master in a tournament.[21]
1979 – Frederic Friedel organizes a match between IM David Levy and Chess 4.8, which is broadcast on German television. Levy and Chess 4.8, running on a CDC Cyber 176, the most powerful computer in the world, fought a grueling 89 move draw.
1980 – Fidelity computers win the World Microcomputer Championships each year from 1980 through 1984. In Germany, Hegener & Glaser release their first Mephisto dedicated chess computer. The USCF prohibits computers from competing in human tournaments except when represented by the chess systems' creators.[74] The Fredkin Prize, offering $100,000 to the creator of the first chess machine to defeat the world chess champion, is established.
1981 – Cray Blitz wins the Mississippi State Championship with a perfect 5–0 score and a performance rating of 2258. In round 4 it defeats Joe Sentef (2262) to become the first computer to beat a master in tournament play and the first computer to gain a master rating.
1984 –  The German Company Hegener & Glaser's Mephisto line of dedicated chess computers begins a long streak of victories (1984–1990) in the World Microcomputer Championship using dedicated computers running programs ChessGenius and Rebel.
1986 – Software Country (see Software Toolworks) released Chessmaster 2000 based on an engine by David Kittinger, the first edition of what was to become the world's best selling line of chess programs.
1987 – Frederic Friedel and physicist Matthias Wüllenweber found Chessbase, releasing the first chess database program.  Stuart Cracraft releases GNU Chess, one of the first 'chess engines' to be bundled with a separate graphical user interface (GUI), chesstool.[75]
1988 – HiTech, developed by Hans Berliner and Carl Ebeling, wins a match against grandmaster Arnold Denker 3½–½. Deep Thought shares first place with Tony Miles in the Software Toolworks Championship, ahead of former world champion Mikhail Tal and several grandmasters including Samuel Reshevsky, Walter Browne and Mikhail Gurevich. It also defeats grandmaster Bent Larsen, making it the first computer to beat a GM in a tournament. Its rating for performance in this tournament of 2745 (USCF scale) was the highest obtained by a computer player.[76][77]
1989 – Deep Thought demolishes David Levy in a 4-game match 0–4, bringing to an end his famous series of wagers starting in 1968.
1990 – On April 25, former world champion Anatoly Karpov lost in a simul to Hegener & Glaser's Mephisto Portorose M68030 chess computer.[78]
1991 – The ChessMachine based on Ed Schröder's Rebel wins the World Microcomputer Chess Championship
1992 – ChessMachine wins the 7th World Computer Chess Championship, the first time a microcomputer beat mainframes. GM John Nunn releases Secrets of Rook Endings, the first book based on endgame tablebases developed by Ken Thompson.
1993 – Deep Thought-2 loses a four-game match against Bent Larsen. Chess programs running on personal computers surpass Mephisto's dedicated chess computers to win the Microcomputer Championship, marking a shift from dedicated chess hardware to software on multipurpose personal computers.
1995 – Fritz 3, running on a 90 Mhz Pentium PC, beats Deep Thought-2 dedicated chess machine, and programs running on several super-computers, to win the 8th World Computer Chess Championships in Hong Kong. This marks the first time a chess program running on commodity hardware defeats specialized chess machines and massive super-computers, indicating a shift in emphasis from brute computational power to algorithmic improvements in the evolution of chess engines.
1996 – IBM's Deep Blue loses a six-game match against Garry Kasparov, 2–4.
1997 – Deep(er) Blue, a highly modified version of the original, wins a six-game match against Garry Kasparov, 3.5–2.5.
2000 – Stefan Meyer-Kahlen and Rudolf Huber draft the Universal Chess Interface, a protocol for GUIs to talk to engines that would gradually become the main form new engines would take.
2002 – Vladimir Kramnik ties an eight-game match against Deep Fritz.
2003 – Kasparov draws a six-game match against Deep Junior and draws a four-game match against X3D Fritz.
2004 – a team of computers (Hydra, Deep Junior and Fritz) wins 8½–3½ against a strong human team formed by Veselin Topalov, Ruslan Ponomariov and Sergey Karjakin, who had an average Elo rating of 2681. Fabien Letouzey releases the source code for Fruit 2.1, an engine quite competitive with the top closed-source engines of the time.  This leads many authors to revise their code, incorporating the new ideas.
2005 – Rybka wins the IPCCC tournament and very quickly afterwards becomes the strongest engine.[79]
2006 – The world champion, Vladimir Kramnik, is defeated 4–2 by Deep Fritz.
2009 – Pocket Fritz. 4 running on a smartphone, wins Copa Mercosur, an International Master level tournament, scoring 9½/10 and earning a performance rating of 2900.[30] A group of pseudonymous Russian programmers release the source code of Ippolit, an engine seemingly stronger than Rybka. This becomes the basis for the engines Robbolito and Ivanhoe, and many engine authors adopt ideas from it.
2010 – Before the World Chess Championship 2010, Topalov prepares by sparring against the supercomputer Blue Gene with 8,192 processors capable of 500 trillion (5 × 1014) floating-point operations per second.[80] Rybka developer, Vasik Rajlich, accuses Ippolit of being a clone of Rybka.
2011 – The ICGA strips Rybka of its WCCC titles.[81][82]
2017 – AlphaZero, a neural net-based digital automaton, beats Stockfish 28–0, with 72 draws, in a 100-game match.
2018 – Efficiently updatable neural network (NNUE) evaluation is invented for computer shogi.[83]
2019 – Leela Chess Zero (LCZero v0.21.1-nT40.T8.610), a chess engine based on AlphaZero, defeats Stockfish 19050918 in a 100-game match with the final score 53.5 to 46.5 to win TCEC season 15.[84]
2020 – NNUE is added to Stockfish evaluation, noticeably increasing its strength.[64][65]
Categorizations[edit]
Dedicated hardware[edit]
These chess playing systems include custom hardware with approx. dates of introduction (excluding dedicated microcomputers):

Belle 1976
Bebe, a strong bit-slice processor 1980
HiTech 1985
ChipTest 1985
Deep Thought 1987
Deep Thought 2 (Deep Blue prototype)~1994
Deep Blue 1996, 1997
Hydra, predecessor was called Brutus 2002
AlphaZero 2017 (used Google's Tensor Processing Units for neural networks, but the hardware is not specific to Chess or games)
MuZero 2019 (similar hardware to its predecessor AlphaZero, non-specific to Chess or e.g. Go), learns the rules of Chess
Commercial dedicated computers[edit]
Boris Diplomat (1979) travel chess computer
Fidelity Voice Chess Challenger (1979), the first talking chess computer
Speech output from Voice Chess Challenger
Milton Bradley Grandmaster (1983), the first commercial self-moving chess computer
Novag Super Constellation (1984), known for its human-like playing style
DGT Centaur (2019), a modern chess computer based on Stockfish running on a Raspberry Pi
In the late 1970s to early 1990s, there was a competitive market for dedicated chess computers. This market changed in the mid-1990s when computers with dedicated processors could no longer compete with the fast processors in personal computers.

Boris in 1977 and Boris Diplomat in 1979, chess computers including pieces and board, sold by Applied Concepts Inc.
Chess Challenger, a line of chess computers sold by Fidelity Electronics from 1977 to 1992.[85] These models won the first four World Microcomputer Chess Championships.[citation needed]
ChessMachine, an ARM-based dedicated computer, which could run two engines:
"The King", which later became the Chessmaster engine, was also used in the TASC R30 dedicated computer.
Gideon, a version of Rebel, in 1992 became the first microcomputer to win the World Computer Chess Championship.[86]
Excalibur Electronics sells a line of beginner strength units.
Mephisto, a line of chess computers sold by Hegener & Glaser. The units won six consecutive World Microcomputer Chess Championships.[citation needed]
Novag sold a line of tactically strong computers, including the Constellation, Sapphire, and Star Diamond brands.
Phoenix Chess Systems makes limited edition units based around StrongARM and XScale processors running modern engines and emulating classic engines.
Saitek sells mid-range units of intermediate strength. They bought out Hegener & Glaser and its Mephisto brand in 1994.
Recently, some hobbyists have been using the Multi Emulator Super System to run the chess programs created for Fidelity or Hegener & Glaser's Mephisto computers on modern 64-bit operating systems such as Windows 10.[87]  The author of Rebel, Ed Schröder has also adapted three of the Hegener & Glaser Mephisto's he wrote to work as UCI engines.[88]

DOS programs[edit]
These programs can be run on MS-DOS, and can be run on 64-bit Windows 10 via emulators such as DOSBox or Qemu:[89]

Chessmaster 2000
Colossus Chess
Fritz 1–3
Kasparov's Gambit
Rebel
Sargon
Socrates II
Notable theorists[edit]
Well-known computer chess theorists include:

Georgy Adelson-Velsky, a Soviet and Israeli mathematician and computer scientist
Hans Berliner, American computer scientist and world correspondence chess champion, design supervisor of HiTech (1988)
Mikhail Botvinnik, Soviet electrical engineer and world chess champion, wrote Pioneer
Alexander Brudno, Russian computer scientist, first elaborated the alphabeta pruning algorithm
Feng-hsiung Hsu, the lead developer of Deep Blue (1986–97)
Professor Robert Hyatt developed Cray Blitz and Crafty[90]
Danny Kopec, American Professor or Computer Science and International Chess Master, developed Kopec-Bratko test
Alexander Kronrod, Soviet computer scientist and mathematician
Professor Monroe Newborn, chairman of the computer chess committee for the Association for Computing Machinery
Claude E. Shannon, American computer scientist and mathematician
Alan Turing, English computer scientist and mathematician
Solving chess[edit]
Main article: Solving chess
The prospects of completely solving chess are generally considered to be rather remote. It is widely conjectured that no computationally inexpensive method to solve chess exists even in the weak sense of determining with certainty the value of the initial position, and hence the idea of solving chess in the stronger sense of obtaining a practically usable description of a strategy for perfect play for either side seems unrealistic today. However, it has not been proven that no computationally cheap way of determining the best move in a chess position exists, nor even that a traditional alpha–beta searcher running on present-day computing hardware could not solve the initial position in an acceptable amount of time. The difficulty in proving the latter lies in the fact that, while the number of board positions that could happen in the course of a chess game is huge (on the order of at least 1043[91] to 1047), it is hard to rule out with mathematical certainty the possibility that the initial position allows either side to force a mate or a threefold repetition after relatively few moves, in which case the search tree might encompass only a very small subset of the set of possible positions. It has been mathematically proven that generalized chess (chess played with an arbitrarily large number of pieces on an arbitrarily large chessboard) is EXPTIME-complete,[92]  meaning that determining the winning side in an arbitrary position of generalized chess provably takes exponential time in the worst case; however, this theoretical result gives no lower bound on the amount of work required to solve ordinary 8x8 chess.
Martin Gardner's Minichess, played on a 5×5 board with approximately 1018 possible board positions, has been solved; its game-theoretic value is 1/2 (i.e. a draw can be forced by either side), and the forcing strategy to achieve that result has been described.
Progress has also been made from the other side: as of 2012, all 7 and fewer pieces (2 kings and up to 5 other pieces) endgames have been solved.

Chess engines[edit]
Main article: Chess engine
A "chess engine" is software that calculates and orders which moves are the strongest to play in a given position.  Engine authors focus on improving the play of their engines, often just importing the engine into a graphical user interface (GUI) developed by someone else.  Engines communicate with the GUI by standardized protocols such as the nowadays ubiquitous Universal Chess Interface developed by Stefan Meyer-Kahlen and Franz Huber. There are others, like the Chess Engine Communication Protocol developed by Tim Mann for GNU Chess and Winboard. Chessbase has its own proprietary protocol, and at one time Millennium 2000 had another protocol used for ChessGenius.  Engines designed for one operating system and protocol may be ported to other OS's or protocols. Chess engines are regularly matched against each other at dedicated chess engine tournaments.

Chess web apps[edit]
In 1997, the Internet Chess Club released its first Java client for playing chess online against other people inside one's webbrowser.[93]  This was probably one of the first chess web apps. Free Internet Chess Server followed soon after with a similar client.[94]  In 2004, International Correspondence Chess Federation opened up a web server to replace their email-based system.[95] Chess.com started offering Live Chess in 2007.[96] Chessbase/Playchess has long had a downloadable client, and added a web-based client in 2013.[97]
Another popular web app is tactics training.  The now defunct Chess Tactics Server opened its site in 2006,[98] followed by Chesstempo the next year,[99] and Chess.com added its Tactics Trainer in 2008.[100] Chessbase added a tactics trainer web app in 2015.[101]
Chessbase took their chess game database online in 1998.[102]  Another early chess game databases was Chess Lab, which started in 1999.[103] New In Chess had initially tried to compete with Chessbase by releasing a NICBase program for Windows 3.x, but eventually, decided to give up on software, and instead focus on their online database starting in 2002.[104]
One could play against the engine Shredder online from 2006.[105]  In 2015, Chessbase added a play Fritz web app,[106] as well as My Games for storing one's games.[107]
Starting in 2007, Chess.com offered the content of the training program, Chess Mentor, to their customers online.[108]  Top GMs such as Sam Shankland and Walter Browne have contributed lessons.

Impact of AI on chess[edit]
Revolutionizing chess strategy[edit]
The introduction of artificial intelligence transformed the game of chess, particularly at the elite levels. AI greatly influenced defensive strategies. It has the capacity to compute every potential move without concern, unlike human players who are bound to emotional and psychological impacts from factors such as stress or tiredness. As a result, many positions once considered not defensible are now recognized as defensible. 
After studying millions of games, chess engines made new analysis and improved the existing theories of opening. These improvements led to the creation of new ideas and changed the way players think throughout all parts of the game.[109]In classical chess, elite players commonly initiate games by making 10 to 15 opening moves that align with established analyses or leading engine recommendations.[110]

Cheating and fair play[edit]
See also: Cheating in chess
Unlike traditional over-the-board tournaments where handheld metal detectors are employed in order to counter players attempts at using electronic assistance, fair-play monitoring in online chess is much more challenging.
During the 2020 European Online Chess Championship, which saw a record participation of nearly 4000 players over 80 participants were disqualified for cheating—most from beginner and youth categories.[111] The event underscored the growing need for advanced detection methods in online competitions.
In response to these issues, chess platforms such as Chess.com developed AI-based statistical models which track improbable moves by a player and compare them to moves that could be made by an engine. Expert examination is conducted for all suspected cases, and the findings are published on a regular basis. FIDE introduced AI behavior-tracking technology to strengthen anti-cheating measures in online events.[112]

Challenges in cheat detection[edit]
AI-based detection systems use a combination of machine learning to track suspicious player actions in different games. This is done by measuring discrepancies between the real moves and the predicted moves derived from the available statistics. Players of unusually high skill level or unusual strategies that can imitate moves characteristic of automated chess systems. Each case is examined by a human expert to ensure that the decision is correct before any actions are made to guarantee fairness and accuracy.[112]

Aligning AI with humans[edit]
The Maia Chess project was began in 2020 by the University of Toronto, Cornell University, and Microsoft Research. Maia Chess is a neural network constructed to impersonate a human’s manner of playing chess based on skill. Each Maia models was tested on 9 sets of 500,000 positions each, covering rating levels from 1100 to 1900. They perform best when predicting moves made by players at their targeted rating level, with lower Maias accurately predicting moves from lower-rated players (around 1100) and higher Maias doing the same for higher-rated players (around 1900). The primary goal of Maia is to develop an AI chess engine that imitates human decision-making rather than focusing on optimal moves. Through personalization across different skill levels, Maia is able to simulate game styles typical for each level more accurately.[113][114]

Chess and LLMs[edit]
While considered something done more for entertainment than for serious play, people have discovered that large language models (LLMs) of the type created in 2018 and beyond such as GPT-3 can be prompted into producing chess moves given proper language prompts.  While inefficient compared to native chess engines, the fact that LLMs can track the board state at all beyond the opening rather than simply recite chess-like phrases in a dreamlike state was considered greatly surprising.  LLM play has a number of quirks compared to engine play; for example, engines don't generally "care" how a board state was arrived at.  However, LLMs seem to produce different quality moves for a chess position reached via strong play compared to the same board state produced via a set of strange preceding moves (which will generally produce weaker and more random moves).[115]

See also[edit]
List of chess software
History of chess engines
Computer checkers
Computer Go
Computer Othello
Computer shogi
Notes[edit]


^ What this means is that chess, like the common fruit fly, is a simple and more accessible and familiar paradigm to experiment with technology that can be used to produce knowledge about other, more complex systems.

^ The first number refers to the number of moves which must be made by each engine, the second number refers to the number of minutes allocated to make all of these moves. The repeating time control means that the time is reset after each multiple of this number of moves is reached. For example, in a 40/4 time control, each engine would have 4 minutes to make 40 moves, then a new 4 minutes would be allocated for the next 40 moves and so on, until the game was complete.


References[edit]


^ Sreedhar, Suhas (2 July 2007). "Checkers, Solved!". IEEE Spectrum. Institute of Electrical and Electronics Engineers.

^ Ensmenger, N. (2012). "Is chess the drosophila of artificial intelligence? A social history of an algorithm". Social Studies of Science. 42 (1): 5–30. doi:10.1177/0306312711424596. PMID 22530382. S2CID 968033.

^ "Stockfish download".

^ Poindexter, Owen. "8 Best Chess Sites and Websites". Wired.

^ "GitHub - official-stockfish/Stockfish". GitHub.

^ "GitHub - LeelaChessZero/lc0". GitHub.

^ "Announcing Torch: New #2 Chess Engine". Chess.com. 2023-07-13. Retrieved 2023-07-14.

^ "lichess-org/stockfish.wasm". GitHub. Retrieved 19 January 2025.

^ "Stockfish FAQ: Can Stockfish use my GPU?". Stockfish. January 2025. Retrieved 19 January 2025.

^ "nnue-pytorch/docs/nnue.md". GitHub.

^ Monroe, Daniel; Chalmers, Philip A. (2024-10-28), Mastering Chess with a Transformer Model, arXiv:2409.12272, retrieved 2024-11-29

^ Dominik Klein (2022), Neural Networks for Chess, p. 49, arXiv:2209.01506

^ "How do you even cheat in chess? Artificial intelligence and Morse code". CNN.

^ http://scid.sourceforge.net SCID.

^ "Chess Assistant Chess Website:: About Us". www.convekta.com. Archived from the original on August 20, 2008.

^ http://www.exachess.com ExaChess for Mac

^ "Chess PGN Master".

^ https://www.facebook.com/chessstudioapp/ [user-generated source]

^ Simon, H.A.; Newell, A. (1958). "Heuristic problem solving: The next advance in operations research" (PDF). Operations Research. 6 (1): 7. doi:10.1287/opre.6.1.1. Retrieved 10 February 2018.

^ a b c d e f g Hapgood, Fred (23–30 December 1982). "Computer chess bad-human chess worse". New Scientist. pp. 827–830. Retrieved 22 January 2015.[permanent dead link‍]

^ a b c Douglas, J R (December 1978). "Chess 4.7 versus David Levy". BYTE. p. 84. Retrieved 17 October 2013.

^ Flock, Emil; Silverman, Jonathan (March 1984). "SPOC / The Chess Master". BYTE. pp. 288–294. Retrieved 8 September 2015.

^ Stinson, Craig (Jan 1982). "Chess Championship: Machines Play, People Watch". Softline. p. 6. Retrieved 13 July 2014.

^ "Rebel vs Anand". Rebel.nl. Retrieved 2010-04-03.

^ "Chess News – Adams vs Hydra: Man 0.5 – Machine 5.5". ChessBase.com. 28 June 2005. Retrieved 2010-04-03.

^ Once Again, Machine Beats Human Champion at Chess New York Times, December 5, 2006

^ "Once Again, Machine Beats Human Champion at Chess". The New York Times. 5 December 2006. Retrieved 30 April 2010.

^ Computer Chess: The Drosophila of AI October 30, 2002

^ Deep Thought wins Fredkin Intermediate Prize, Hans Berliner

^ a b "Pocket Fritz 4 wins Copa Mercosur". Chess.co.uk. Archived from the original on 2011-09-30. Retrieved 2010-04-03.

^ Stanislav Tsukrov, Pocket Fritz author. Pocket Fritz 4 searches less than 20,000 positions per second.

^ "World chess champion Magnus Carlsen: 'The computer never has been an opponent'". Deutsche Welle. 16 April 2016. Retrieved 26 August 2016.

^ a b "20 Years Later, Humans Still No Match For Computers On The Chessboard". NPR.org. 2016. Retrieved 28 June 2020.

^ Wheland, Norman D. (October 1978). "A Computer Chess Tutorial". BYTE. p. 168. Retrieved 17 October 2013.

^ (Shannon 1950)

^ Levy & Newborn (1991), pp. 144–148

^ Nunn (2002), p. 49

^ Kirill Kryukov. "Endgame Tablebases Online". Kirill-kryukov.com. Retrieved 2010-04-03.

^ "Open chess diary 301–320". Xs4all.nl. Retrieved 2010-04-03.

^ http://tb7.chessok.com Lomonosov website allowing registered user to access 7-piece tablebase, and a forum with positions found.

^ "Who wins from this? (chess puzzle)" An example chess position found from the Lomonosov chess tablebase.

^ The Rybka Lounge / Computer Chess / Tablebase sizes, http://rybkaforum.net/cgi-bin/rybkaforum/topic_show.pl?tid=9380 Archived 2017-06-27 at the Wayback Machine, 19th June 2012

^ "7-piece Syzygy tablebases are complete". lichess.org. 19 August 2018. Retrieved 2023-10-02.

^ "Useful data". GitHub. Retrieved 2023-10-12.

^ "TCEC Openings FAQ". tcec-chess.com. Retrieved 2023-10-12.

^ CEGT 40/20, Chess Engines Grand Tournament, 12 October 2008, archived from the original on 1 March 2012, retrieved 21 October 2008

^ Computerschach und Spiele – Eternal Rating, Computerschach und Spiele, 18 March 2007, retrieved 21 May 2008

^ The SSDF Rating List, Swedish Chess Computer Association, 26 September 2008, retrieved 20 October 2008

^ BayesianElo Ratinglist of WBEC Ridderkerk, retrieved 20 July 2008

^ "Gambit Rating List". Home of the Dutch Rebel. January 30, 2021. Retrieved December 12, 2021.

^ "FGRL". FastGM's Rating List. Retrieved December 12, 2010.

^ "IPON". Ingo Bauer. November 16, 2016. Archived from the original on January 25, 2019. Retrieved February 3, 2016.

^ a b CCRL, http://ccrl.chessdom.com/ Archived 2022-01-21 at the Wayback Machine, 14 November 2021

^ CCRL Discussion Board, http://kirill-kryukov.com/chess/discussion-board/viewtopic.php?f=7&t=2808, 19 June 2012

^ Adam's Computer Chess Pages, http://adamsccpages.blogspot.co.uk/2012/05/ccrl.html, 19 June 2012

^ Thurn, Sebastian (1995), Learning to Play the Game of Chess (PDF), MIT Press, retrieved 12 December 2021

^ Levinson, Robert (1989), A Self-Learning, Pattern-Oriented Chess Program, vol. 12, ICCA Journal

^ Lai, Matthew (4 September 2015), Giraffe: Using Deep Reinforcement Learning to Play Chess, arXiv:1509.01549v1

^ Silver, David; Hubert, Thomas; Schrittwieser, Julian; Antonoglou, Ioannis; Lai, Matthew; Guez, Arthur; Lanctot, Marc; Sifre, Laurent; Kumaran, Dharshan; Graepel, Thore; Lillicrap, Timothy; Simonyan, Karen; Hassabis, Demis (2017). "Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm". arXiv:1712.01815 [cs.AI].

^ Schrittwieser, Julian; Antonoglou, Ioannis; Hubert, Thomas; Simonyan, Karen; Sifre, Laurent; Schmitt, Simon; Guez, Arthur; Lockhart, Edward; Hassabis, Demis; Graepel, Thore; Lillicrap, Timothy (2020). "Mastering Atari, Go, chess and shogi by planning with a learned model". Nature. 588 (7839): 604–609. arXiv:1911.08265. Bibcode:2020Natur.588..604S. doi:10.1038/s41586-020-03051-4. PMID 33361790. S2CID 208158225.

^ Yu Nasu (April 28, 2018). "Efficiently Updatable Neural-Network-based Evaluation Function for computer Shogi" (PDF) (in Japanese).

^ Yu Nasu (April 28, 2018). "Efficiently Updatable Neural-Network-based Evaluation Function for computer Shogi (Unofficial English Translation)" (PDF). GitHub.

^ Noda, Hisayori (30 May 2020). "Release stockfish-nnue-2020-05-30". Github. Retrieved 12 December 2021.

^ a b "Introducing NNUE Evaluation". 6 August 2020.

^ a b Joost VandeVondele (July 25, 2020). "official-stockfish / Stockfish, NNUE merge". GitHub.

^ "Venki Ramakrishnan: Will Computers Become Our Overlords?". Possible Minds: Twenty-five Ways of Looking at AI (Kindle ed.). Penguin Press. 2019. p. 174. ISBN 978-0525557999.

^ Chess, a subsection of chapter 25, Digital Computers Applied to Games, of Faster than Thought, ed. B. V. Bowden, Pitman, London (1953). Online.

^ A game played by Turing's chess algorithm

^ "Chessville – Early Computer Chess Programs – by Bill Wall – Bill Wall's Wonderful World of Chess". Archive.is. Archived from the original on 21 July 2012. Retrieved 1 December 2014.{{cite web}}:  CS1 maint: bot: original URL status unknown (link)

^ David Bronstein v M-20, replay at Chessgames.com

^ Dennis Ritchie (June 2001). "Ken, Unix and Games". ICGA Journal. 24 (2).

^ "Appendix CHESS 4.5: Competition in 1976" (PDF).

^ "Oral History of Peter Jennings | Mastering the Game | Computer History Museum".

^ "New Restrictions". BYTE. January 1981. p. 292. Retrieved 18 October 2013.

^ "GNU's Bulletin, vol. 1 no. 2".

^ Hsu (2002) p. 292

^ Newborn (1997) p. 159

^ Selective Search. June 1990

^ International Paderborn Computer Chess Championship 2005

^ "Challenger uses supercomputer at the world chess championship". Chessbase. 25 May 2010.

^ "Rybka disqualified and banned from World Computer Chess Championships | ChessVibes". www.chessvibes.com. Archived from the original on 30 March 2014.

^ Riis, Dr. Søren (2 January 2012). "A Gross Miscarriage of Justice in Computer Chess (part one)". Chessbase News. Retrieved 19 February 2012.

^ Yu Nasu (2018). ƎUИИ Efficiently Updatable Neural-Network based Evaluation Functions for Computer Shogi. Ziosoft Computer Shogi Club, pdf (Japanese with English abstract)

^ https://cd.tcecbeta.club/archive.html?season=15&div=sf&game=1 TCEC season 15

^ Sousa, Ismenio. "Fidelity Chess Challenger 1 – World's First Chess Computer". Retrieved 25 September 2016.

^ van den Herik, H.J.; Herschberg, I. S. (1992). "The 7th World Computer-Chess Championship: Report on the tournament, Madrid, Spain, November 23-27, 1992". ICCA Journal. 15 (4): 208–209.

^ "Download | Home of the Dutch Rebel". Rebel13.nl. Retrieved 2022-08-31.

^ "Dedicated as UCI | Home of the Dutch Rebel". Rebel13.nl. Retrieved 2022-08-31.

^ "More DOS oldies". Archived from the original on 2018-12-03. Retrieved 2018-12-02.

^ "Dr. Robert Hyatt's home page". Cis.uab.edu. 2004-02-01. Retrieved 2010-04-03.

^ The size of the state space and game tree for chess were first estimated in Claude Shannon (1950), "Programming a Computer for Playing Chess" (PDF), Philosophical Magazine, 41 (314), archived from the original (PDF) on 6 July 2010, retrieved 30 December 2008 Shannon gave estimates of 1043 and 10120 respectively, smaller than the estimates in the Game complexity table, which are from Victor Allis's thesis. See Shannon number for details.

^ Aviezri Fraenkel; D. Lichtenstein (1981), "Computing a perfect strategy for n×n chess requires time exponential in n", J. Combin. Theory Ser. A, 31 (2): 199–214, doi:10.1016/0097-3165(81)90016-9

^ "CoffeeHouse: The Internet Chess Club Java Interface". Archived from the original on 1997-06-20. Retrieved 2019-07-08.

^ "FICS - Free Internet Chess Server". Archived from the original on 1998-12-12. Retrieved 2019-07-08.

^ "Archived copy". Archived from the original on 2004-08-31. Retrieved 2004-08-31.{{cite web}}:  CS1 maint: archived copy as title (link)

^ "Play Daily (Correspondence) Chess". Archived from the original on 2007-10-06.

^ "Play Chess Online for Free". play.chessbase.com. Archived from the original on 17 December 2013. Retrieved 11 January 2022.

^ "Chess Tactics Server". Archived from the original on 2006-04-08. Retrieved 2006-04-08.

^ "Chess Tactics". Archived from the original on 2007-06-13. Retrieved 2007-06-13.

^ "Chess Puzzles - Improve Your Chess by Solving Tactics". Archived from the original on 2008-02-18. Retrieved 2008-02-18.

^ "Chess Tactics Online". Archived from the original on 2015-05-04.

^ "Chessbase Online, Searching a high quality database of Chessgames. Free Chess Games.ChessBase-Online". www.chessbase-online.com. Archived from the original on 11 May 2000. Retrieved 11 January 2022.

^ "Java chess games: Database search, analysis". Archived from the original on 1999-02-19. Retrieved 2019-07-08.

^ "NICBase Online". Archived from the original on 2002-10-08. Retrieved 2002-10-08.

^ "Play Chess Online - Shredder Chess". Archived from the original on 2006-12-05. Retrieved 2006-12-05.

^ "Home". fritz.chessbase.com.

^ "Home". mygames.chessbase.com.

^ "Chess Lessons - Learn with Online Courses". Archived from the original on 2007-12-14. Retrieved 2007-12-14.

^ ChessBase. (2024). How the AI revolution impacted chess (1/2). ChessBase. ChessBase.com. Accessed 2025 Feb 11.

^ Kahn, J. (2019). Can Chess Survive Artificial Intelligence? The New Atlantis, (58), 16-35. https://www.thenewatlantis.com/publications/can-chess-survive-artificial-intelligence

^ Cheating and fair play. European online chess championship: Over 80 players disqualified for violating fair play rules. MumbaiMirror.indiatimes.com. May 29, 2020. Accessed 2025 Feb 11.

^ a b  Duca Iliescu DM. The Impact of Artificial Intelligence on the Chess World. JMIR Serious Games. 2020 Dec 10;8(4):e24049. doi: 10.2196/24049. PMID: 33300493; PMCID: PMC7759436. 

^ @inproceedings{McIlroy_Young_2020, series={KDD ’20},
   title={Aligning Superhuman AI with Human Behavior: Chess as a Model System},
   url={https://arxiv.org/abs/2006.01855},
   DOI={10.1145/3394486.3403219},
   booktitle={Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining},
   publisher={ACM},
   author={McIlroy-Young, Reid and Sen, Siddhartha and Kleinberg, Jon and Anderson, Ashton},
   year={2020},
   month=aug, pages={1677–1687},
   collection={KDD ’20} }

^ "AI has dominated chess for 25 years, but now it wants to lose". Science Focus. Immediate Media Company Ltd. 2023-02-13. Retrieved 2025-02-11.

^ "OK, I can partly explain the LLM chess weirdness now". November 21, 2024.


 This article incorporates text by Chess Programming Wiki available under the CC BY-SA 3.0 license.

Sources[edit]
Hsu, Feng-hsiung (2002), Behind Deep Blue: Building the Computer that Defeated the World Chess Champion, Princeton University Press, ISBN 0-691-09065-3
Levy, David; Newborn, Monty (1991), How Computers Play Chess, Computer Science Press, ISBN 0-7167-8121-2
Newborn, Monty (1975), Computer Chess, Academic Press, New York
Newborn, Monty (1997), Kasparov versus Deep Blue: Computer Chess Comes of Age, Springer, ISBN 0-387-94820-1 (This book actually covers computer chess from the early days through the first match between Deep Blue and Garry Kasparov.)
Nunn, John (2002), Secrets of Pawnless Endings, Gambit Publications, ISBN 1-901983-65-X
Shannon, Claude E. (1950), "Programming a Computer for Playing Chess" (PDF), Philosophical Magazine, Ser.7, Vol. 41 (314), archived from the original (PDF) on 6 July 2010, retrieved 21 June 2009
Mastering the Game: A History of Computer Chess at Computer History Museum
Bill Wall's Computer Chess History Timeline
Further reading[edit]
New Architectures in Computer Chess – Thesis on How to Build A Chess Engine
Coles, L. Stephen (October 30, 2002), Computer Chess: The Drosophila of AI, Dr. Dobb's Journal
Huberman (Liskov), Barbara Jane (1968), A program to play chess end games, Stanford University Department of Computer Science, Technical Report CS 106, Stanford Artificial Intelligence Project Memo AI-65
Lasar, Matthew (2011). Brute force or intelligence? The slow rise of computer chess". Ars Technica.
Newborn, Monty (1996). Outsearching Kasparov, American Mathematical Society's Proceeding of Symposia in Applied Mathematics: Mathematical Aspects of Artificial Intelligence, v. 55, pp 175–205, 1998. Based on paper presented at the 1996 Winter Meeting of the AMS, Orlando, Florida, Jan 9–11, 1996.
Newborn, Monty (2000). Deep Blue's contribution to AI, Annals of Mathematics and Artificial Intelligence, v. 28, pp. 27–30, 2000.
Newborn, Monty (2006). Theo and Octopus at the 2006 World Championship for Automated Reasoning Programs, Seattle, Washington, August 18, 2006
Stiller, Lewis (1996), Multilinear Algebra and Chess Endgames (PDF), Berkeley, California: Mathematical Sciences Research Institute, Games of No Chance, MSRI Publications, Volume 29, retrieved 21 June 2009
External links[edit]



Look up computer chess in Wiktionary, the free dictionary.




Wikimedia Commons has media related to Computer chess.

List of chess engine ratings and game files in PGN format
Mastering the Game: A History of Computer Chess at the Computer History Museum
ACM Computer Chess by Bill Wall
"Computer Chess" by Edward Winter
Computer Chess Information and Resources Archived 2019-01-18 at the Wayback Machine – blog following the creation of a computer chess engine
Defending Humanity's Honor, an article by Tim Krabbé about "anti-computer style" chess
A guide to Endgame Tablebases
GameDev.net – Chess Programming by François-Dominic Laramée Part 1 Archived 2011-09-18 at the Wayback Machine 2 Archived 2011-09-27 at the Wayback Machine 3 Archived 2011-09-19 at the Wayback Machine 4 Archived 2011-09-19 at the Wayback Machine 5 Archived 2011-09-20 at the Wayback Machine 6 Archived 2011-08-07 at the Wayback Machine
Colin Frayn's Computer Chess Theory Page
""How REBEL Plays Chess" by Ed Schröder" (PDF). (268 KB)
"Play chess with God" Archived 2012-11-29 at archive.today – for playing chess against Ken Thompson's endgame database
Chess programming wiki
Computer Chess Club Forums
The Strongest Computer Chess Engines Over Time
Media[edit]
The History of Computer Chess: An AI Perspective Archived 2006-06-14 at the Wayback Machine – a full lecture featuring Murray Campbell (IBM Deep Blue Project), Edward Feigenbaum, David Levy, John McCarthy, and Monty Newborn. at Computer History Museum
vteChessOutline
Chess theory
Chess titles
Grandmaster
Computer chess
glossary
matches
engines
software
Correspondence chess
FIDE
Glossary
Online chess
Premove
Internet chess server
list
Rating system
world rankings
norms
Variants
List
World records
Equipment
Chess set
chessboard
Dubrovnik chess set
Staunton chess set
Chess pieces
King
Queen
Rook
Bishop
Knight
Pawn
Fairy
Chess clock
Chess table
Score sheets
History
Timeline
Versus de scachis
Göttingen manuscript
Charlemagne chessmen
Lewis chessmen
Romantic chess
Hypermodernism
Soviet chess school
Top player comparison
Geography of chess
Africa
South Africa
China
Europe
Armenia
Spain
India
Notable games
List of chess players
amateurs
female
grandmasters
Women in chess
Transgender people in chess
Chess museums
Bobby Fischer Center
Gökyay Association Chess Museum
World Chess Hall of Fame
Rules
Castling
Cheating in chess
Check
Checkmate
Draw
by agreement
Fifty-move rule
Perpetual check
Stalemate
Threefold repetition
En passant
Pawn promotion
Time control
Fast chess
Touch-move rule
White and Black
Terms
Blunder
Chess notation
algebraic
descriptive
PGN
annotation symbols
symbols in Unicode
Fianchetto
Gambit
Key square
King walk
Open file
Half-open file
Outpost
Pawns
backward
connected
doubled
isolated
passed
Swindle
Tempo
Transposition
Trap
Tactics
Artificial castling
Battery
Alekhine's gun
Block
Checkmate patterns
Combination
Decoy
Deflection
Desperado
Discovered attack
Double check
Fork
Interference
Overloading
Pawn storm
Pin
Sacrifice
Queen sacrifice
Skewer
Undermining
Windmill
X-ray
Zwischenzug
Strategy
Compensation
Exchange
the exchange
Initiative
first-move advantage
Middlegame
Pawn structure
Hedgehog
Isolated Queen's Pawn
Maróczy Bind
Minority attack
Piece values
Prophylaxis
School of chess
OpeningsFlank opening
Benko Opening
Bird's Opening
Dunst Opening
English Opening
Grob's Attack
Larsen's Opening
Zukertort Opening
King's Indian Attack
Réti Opening
King's Pawn Game
Alekhine's Defence
Caro–Kann Defence
French Defence
Modern Defence
Nimzowitsch Defence
Open Game
Four Knights Game
Giuoco Piano
Italian Game
King's Gambit
Petrov's Defence
Philidor Defence
Ponziani Opening
Ruy Lopez
Semi-Italian Opening
Scotch Game
Two Knights Defense
Vienna Game
Owen's Defence
Pirc Defence
Austrian Attack
Scandinavian Defense
Sicilian Defence
Alapin
Dragon/Accelerated Dragon
Najdorf
Scheveningen
Queen's Pawn Game
Budapest Gambit
Colle System
Dutch Defence
English Defence]]
Indian Defence
Benoni Defence
Modern Benoni
Bogo-Indian Defence
Catalan Opening
Grünfeld Defence
King's Indian Defence
Nimzo-Indian Defence
Old Indian Defense
Queen's Indian Defence
London System
Richter–Veresov Attack
Queen's Gambit
Accepted
Declined
Slav Defence
Semi-Slav Defence
Chigorin Defense
Torre Attack
Trompowsky Attack
Other
List of openings
theory table
List of chess gambits
Irregular
Bongcloud Attack
Fool's mate
Scholar's mate
Endgames
Bishop and knight checkmate
King and pawn vs. king
Opposite-coloured bishops
Pawnless endgame
Queen and pawn vs. queen
Queen vs. pawn
Queen vs. rook
Rook and bishop vs. rook
Rook and pawn vs. rook
Lucena position
Philidor position
Strategy
fortress
opposition
Tarrasch rule
triangulation
Zugzwang
Study
Tablebase
Two knights endgame
Wrong bishop
Wrong rook pawn
Tournaments
List of strong chess tournaments
Chess Olympiad
Women
World Chess Championship
List
Candidates Tournament
Chess World Cup
FIDE Grand Prix
Other world championships
Women
Team
Rapid
Blitz
Junior
Youth
Senior
Amateur
Chess composition
Solving
Computer chess championships
CCC
CSVN
North American
TCEC
WCCC
WCSCC
Art and media
Caïssa
Chess aesthetics
Chess in the arts
early literature
film
novels
paintings
poetry
short stories
Chess books
opening books
endgame literature
Oxford Companion
Chess libraries
Chess newspaper columns
Chess periodicals
Related
Arbiter
Chess boxing
Chess club
Chess composer
Chess engine
AlphaZero
Deep Blue
Leela Chess Zero
Stockfish
Chess problem
glossary
joke chess
Chess prodigy
Elo rating system
Simultaneous exhibition
Tie-breaking in Swiss-system tournaments
Solving chess

 Chess portal
Category

Authority control databases: National GermanyUnited StatesIsrael



